# Module 2: Project Architecture & Setup

**Duration**: 45 minutes
**Difficulty**: Beginner
**Prerequisites**: Module 1 completed

---

## Learning Objectives

By the end of this module, you will understand:

âœ… The overall system architecture and data flow
âœ… Each microservice's role and responsibility
âœ… How services communicate via Kafka
âœ… The CQRS pattern implementation
âœ… How to set up and run the project locally
âœ… How to verify that all services are working

---

## Table of Contents

1. [System Architecture Overview](#1-system-architecture-overview)
2. [Microservices Breakdown](#2-microservices-breakdown)
3. [Data Flow Walkthrough](#3-data-flow-walkthrough)
4. [Infrastructure Components](#4-infrastructure-components)
5. [CQRS Pattern Implementation](#5-cqrs-pattern-implementation)
6. [Project Structure](#6-project-structure)
7. [Environment Setup](#7-environment-setup)
8. [Running the Project](#8-running-the-project)
9. [Verification and Testing](#9-verification-and-testing)
10. [Summary](#10-summary)

---

## 1. System Architecture Overview

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PRESENTATION LAYER                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Dashboard UI (React)                         Port: 3000     â”‚  â”‚
â”‚  â”‚  - Real-time event visualization                             â”‚  â”‚
â”‚  â”‚  - Search and filtering                                      â”‚  â”‚
â”‚  â”‚  - Charts and statistics                                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“ HTTP GET
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          API LAYER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Elastic Query Service                        Port: 8084     â”‚  â”‚
â”‚  â”‚  - REST API endpoints                                        â”‚  â”‚
â”‚  â”‚  - OpenAPI/Swagger documentation                             â”‚  â”‚
â”‚  â”‚  - Pagination and sorting                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“ Query
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SEARCH LAYER                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Elasticsearch                                Port: 9200     â”‚  â”‚
â”‚  â”‚  - Full-text search index                                    â”‚  â”‚
â”‚  â”‚  - 3 shards, 1 replica                                       â”‚  â”‚
â”‚  â”‚  - Real-time queries                                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†‘ Index
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       PROCESSING LAYER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Elasticsearch Svc   â”‚  â”‚ Kafka Streams Svc   â”‚                  â”‚
â”‚  â”‚ Port: 8083          â”‚  â”‚ Port: 8082          â”‚                  â”‚
â”‚  â”‚ - Consume events    â”‚  â”‚ - Stream processing â”‚                  â”‚
â”‚  â”‚ - Transform to docs â”‚  â”‚ - Real-time analyticsâ”‚                 â”‚
â”‚  â”‚ - Batch index       â”‚  â”‚ - Word counting     â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Kafka Consumer Service                      Port: 8081      â”‚   â”‚
â”‚  â”‚ - Consume events in batches                                 â”‚   â”‚
â”‚  â”‚ - Calculate metrics and statistics                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†‘ Subscribe
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        EVENT BUS LAYER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Apache Kafka Cluster                                        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚  â”‚  â”‚ Broker 1   â”‚  â”‚ Broker 2   â”‚  â”‚ Broker 3   â”‚            â”‚  â”‚
â”‚  â”‚  â”‚ :19092     â”‚  â”‚ :29092     â”‚  â”‚ :39092     â”‚            â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚  â”‚                                                              â”‚  â”‚
â”‚  â”‚  Topics:                                                     â”‚  â”‚
â”‚  â”‚  - social-events (3 partitions, RF=3)                       â”‚  â”‚
â”‚  â”‚  - social-events-filtered                                   â”‚  â”‚
â”‚  â”‚  - social-events-word-count                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Schema Registry                             Port: 8081     â”‚  â”‚
â”‚  â”‚  - Stores Avro schemas                                       â”‚  â”‚
â”‚  â”‚  - Validates schema compatibility                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†‘ Publish
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PRODUCER LAYER                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Event Stream Service                         Port: 8080     â”‚  â”‚
â”‚  â”‚  - Generate mock social media events                         â”‚  â”‚
â”‚  â”‚  - Serialize to Avro format                                  â”‚  â”‚
â”‚  â”‚  - Publish to Kafka                                          â”‚  â”‚
â”‚  â”‚  - 60 events/minute                                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COORDINATION LAYER                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Zookeeper                                   Port: 2181      â”‚  â”‚
â”‚  â”‚  - Kafka cluster coordination                                â”‚  â”‚
â”‚  â”‚  - Leader election                                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Microservices Breakdown

### Service 1: Event Stream Service

**Port**: 8080
**Language**: Java 21 / Spring Boot 3.2.5

**Responsibility**: Event Generation

**What It Does**:
- Generates realistic social media-style events
- Creates 60 events per minute (configurable)
- Serializes events to Apache Avro format
- Publishes events to Kafka topic `social-events`

**Key Components**:
- `EnhancedMockStreamRunner`: Event generation logic
- `AvroKafkaProducer`: Kafka producer wrapper
- `SocialEventAvroModel`: Avro-generated event model

**Entry Point**:
```
/event-stream-service/src/main/java/.../EventStreamServiceApplication.java
```

**Configuration**:
```yaml
# Key settings
event-stream:
  sleep-ms: 1000              # 1 event per second
  message-count: 60           # Generate 60 messages

kafka:
  topic-name: social-events
  num-partitions: 3
  replication-factor: 3
```

---

### Service 2: Kafka Consumer Service

**Port**: 8081
**Language**: Java 21 / Spring Boot 3.2.5

**Responsibility**: General-Purpose Event Processing

**What It Does**:
- Consumes events from `social-events` topic
- Processes events in batches (500 records)
- Calculates metrics (consumed, processed, failed)
- Logs statistics every 30 seconds
- Uses 3 concurrent consumer threads

**Key Components**:
- `SocialEventKafkaConsumer`: Main consumer logic
- Batch processing with manual acknowledgment
- Micrometer metrics integration

**Consumer Group**: `social-events-consumer-group`

**Entry Point**:
```
/kafka-consumer-service/src/main/java/.../KafkaConsumerServiceApplication.java
```

**Configuration**:
```yaml
kafka-consumer:
  group-id: social-events-consumer-group
  auto-offset-reset: earliest
  batch-listener: true
  max-poll-records: 500
  concurrency: 3               # 3 consumer threads
```

---

### Service 3: Kafka Streams Service

**Port**: 8082
**Language**: Java 21 / Spring Boot 3.2.5

**Responsibility**: Real-Time Stream Processing

**What It Does**:
- Processes event stream in real-time
- Filters events that have text content
- Extracts words and counts frequency (5-minute windows)
- Aggregates events by user
- Produces derived topics

**Key Components**:
- `SocialEventStreamsTopology`: Stream processing topology
- Stateless transformations (filter, map)
- Stateful aggregations (count, windowing)

**Input Topic**: `social-events`
**Output Topics**:
- `social-events-filtered`: Events with text
- `social-events-word-count`: Word frequency analytics

**Application ID**: `social-events-streams-app`

**Entry Point**:
```
/kafka-streams-service/src/main/java/.../KafkaStreamsServiceApplication.java
```

**Stream Processing**:
```
social-events
    â†“ filter (text not null)
social-events-filtered
    â†“ flatMap (extract words)
    â†“ groupBy word
    â†“ window (5-minute tumbling)
    â†“ count
social-events-word-count
```

---

### Service 4: Elasticsearch Service

**Port**: 8083
**Language**: Java 21 / Spring Boot 3.2.5

**Responsibility**: Search Indexing

**What It Does**:
- Consumes events from `social-events` topic
- Transforms Avro models to Elasticsearch documents
- Batch indexes to `social-events-index`
- Creates index with 3 shards, 1 replica
- Enables full-text search on text field

**Key Components**:
- `SocialEventKafkaToElasticConsumer`: Kafka consumer
- `ElasticIndexClient`: Elasticsearch batch indexer
- `SocialEventIndexModel`: Elasticsearch document model

**Consumer Group**: `elasticsearch-consumer-group`

**Entry Point**:
```
/elasticsearch-service/src/main/java/.../ElasticsearchIndexingServiceApplication.java
```

**Transformation**:
```
SocialEventAvroModel           â†’    SocialEventIndexModel
â”œâ”€â”€ userId: Long               â†’    â”œâ”€â”€ userId: Long
â”œâ”€â”€ id: Long                   â†’    â”œâ”€â”€ id: String (primary key)
â”œâ”€â”€ text: String               â†’    â”œâ”€â”€ text: String (analyzed)
â””â”€â”€ createdAt: Long            â†’    â””â”€â”€ createdAt: Date (sortable)
```

**Index Configuration**:
```json
{
  "index": "social-events-index",
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "refresh_interval": "1s"
  }
}
```

---

### Service 5: Elastic Query Service (REST API)

**Port**: 8084
**Language**: Java 21 / Spring Boot 3.2.5

**Responsibility**: Query Interface

**What It Does**:
- Provides HTTP REST API for querying events
- Queries Elasticsearch index
- Supports pagination and sorting
- Full-text search on text field
- Returns JSON responses

**Key Components**:
- `ElasticQueryController`: REST controller
- `ElasticQueryClient`: Elasticsearch query client
- `SocialEventQueryResponseModel`: API response model

**API Endpoints**:
```
GET  /api/v1/events/{id}                  â†’ Get event by ID
GET  /api/v1/events?page=0&size=20        â†’ Get all events (paginated)
GET  /api/v1/events/search?text=kafka     â†’ Full-text search
GET  /api/v1/events/user/{userId}         â†’ Get events by user
```

**Entry Point**:
```
/elastic/elastic-query-service/src/main/java/.../ElasticQueryServiceApplication.java
```

**Documentation**:
- OpenAPI/Swagger UI: http://localhost:8084/swagger-ui.html

---

### Service 6: Dashboard UI

**Port**: 3000
**Framework**: React 18 + Vite + Tailwind CSS

**Responsibility**: Real-Time Visualization

**What It Does**:
- Displays events in real-time (auto-refresh every 5 seconds)
- Full-text search interface
- Event timeline charts (Recharts)
- Statistics dashboard (total events, unique users, rate)
- Service health monitoring
- Responsive design

**Key Components**:
```
src/
â”œâ”€â”€ App.jsx                    â†’ Main application
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ EventsList.jsx         â†’ Event table
â”‚   â”œâ”€â”€ SearchBar.jsx          â†’ Search input
â”‚   â”œâ”€â”€ EventsChart.jsx        â†’ Timeline chart
â”‚   â”œâ”€â”€ StatsCard.jsx          â†’ Metric display
â”‚   â””â”€â”€ ServiceStatus.jsx      â†’ Health indicators
```

**Technology Stack**:
- **React 18**: Component framework
- **Vite**: Build tool (fast HMR)
- **Tailwind CSS**: Utility-first styling
- **Recharts**: Chart visualization
- **Axios**: HTTP client

**API Integration**:
```javascript
// Polls REST API every 5 seconds
const fetchEvents = async () => {
  const response = await axios.get(
    'http://localhost:8084/api/v1/events?page=0&size=20'
  );
  setEvents(response.data.content);
};

useEffect(() => {
  fetchEvents();
  const interval = setInterval(fetchEvents, 5000);
  return () => clearInterval(interval);
}, []);
```

---

## 3. Data Flow Walkthrough

### End-to-End Event Journey

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Event Generation                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Event Stream Service (Port 8080)
  â†“
EnhancedMockStreamRunner generates event every 1000ms:
  {
    "userId": 42,
    "id": 1234567890,
    "text": "Learning Spring Boot and Kafka is awesome!",
    "createdAt": 1700500000000
  }
  â†“
Serialize to Avro binary format (schema from Registry)
  â†“
AvroKafkaProducer publishes to topic "social-events"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Kafka Cluster Distribution                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Kafka determines partition:
  hash(userId=42) % 3 = Partition 1
  â†“
Event stored in Partition 1 on all 3 brokers (RF=3):
  - Broker 1 (leader)
  - Broker 2 (replica)
  - Broker 3 (replica)
  â†“
Event assigned offset, e.g., 15432

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Parallel Consumption (3 Independent Paths)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PATH A: General Processing
  â†“
Kafka Consumer Service (Port 8081)
  - Consumer Group: "social-events-consumer-group"
  - Fetches batch of up to 500 events
  - Processes each event
  - Updates metrics (consumed, processed, failed)
  - Logs statistics
  - Commits offset

PATH B: Stream Processing
  â†“
Kafka Streams Service (Port 8082)
  - Application ID: "social-events-streams-app"
  - Reads event from stream
  - Filters: text != null âœ“ (passes filter)
  - Publishes to "social-events-filtered"
  - Extracts words: ["learning", "spring", "boot", "kafka", "awesome"]
  - Groups by word, windows by 5 minutes
  - Increments count for each word
  - Publishes to "social-events-word-count"

PATH C: Search Indexing
  â†“
Elasticsearch Service (Port 8083)
  - Consumer Group: "elasticsearch-consumer-group"
  - Fetches event from Kafka
  - Transforms Avro â†’ Elasticsearch document:
      {
        "id": "1234567890",
        "userId": 42,
        "text": "Learning Spring Boot and Kafka is awesome!",
        "createdAt": "2023-11-20T10:00:00Z"
      }
  - Batch indexes to "social-events-index"
  - Document becomes searchable within ~1 second

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Query API Layer                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User queries via REST API (Port 8084):
  GET /api/v1/events/search?text=kafka
  â†“
ElasticQueryController receives request
  â†“
ElasticQueryClient queries Elasticsearch:
  {
    "query": {
      "match": {
        "text": "kafka"
      }
    }
  }
  â†“
Elasticsearch returns matching documents
  â†“
Transform to SocialEventQueryResponseModel
  â†“
Return JSON response to client

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: UI Visualization                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Dashboard UI (Port 3000):
  - Polls API every 5 seconds: GET /api/v1/events
  - Receives JSON array of events
  - Updates React state
  - Re-renders components:
    â€¢ EventsList shows event in table
    â€¢ EventsChart plots event on timeline
    â€¢ StatsCard increments total count
    â€¢ ServiceStatus shows all services healthy
  â†“
User sees event in real-time!
```

**Total Latency**: < 5 seconds from generation to searchable and visible in UI.

---

## 4. Infrastructure Components

### Kafka Cluster

**Configuration**:
- **Brokers**: 3 (ports 19092, 29092, 39092)
- **Zookeeper**: 1 instance (port 2181)
- **Schema Registry**: 1 instance (port 8081)

**Topics**:
| Topic Name | Partitions | Replication Factor | Purpose |
|------------|------------|-------------------|---------|
| `social-events` | 3 | 3 | Main event stream |
| `social-events-filtered` | 3 | 3 | Filtered events (from Streams) |
| `social-events-word-count` | 3 | 3 | Word count analytics |
| `social-events.DLQ` | 1 | 3 | Dead letter queue (failed events) |

**Replication Strategy**:
```
Partition 0:
  Leader:   Broker 1
  Replicas: Broker 2, Broker 3

Partition 1:
  Leader:   Broker 2
  Replicas: Broker 1, Broker 3

Partition 2:
  Leader:   Broker 3
  Replicas: Broker 1, Broker 2
```

Benefits:
- **High Availability**: Survives single broker failure
- **Load Distribution**: Reads/writes spread across brokers
- **Data Durability**: 3 copies of each event

### Elasticsearch Cluster

**Configuration**:
- **Nodes**: 1 (single-node for development)
- **Port**: 9200 (HTTP), 9300 (Transport)
- **Version**: 8.11.0

**Index**: `social-events-index`
- **Shards**: 3 (for parallelism)
- **Replicas**: 1 (for fault tolerance)
- **Refresh Interval**: 1 second

**Kibana**: Port 5601 (visualization and management)

### Schema Registry

**Purpose**: Centralized Avro schema management

**Benefits**:
- **Schema Evolution**: Add fields without breaking consumers
- **Validation**: Reject incompatible schema changes
- **Efficiency**: Schemas stored once, referenced by ID

**Compatibility Modes**:
- **Backward**: New schema can read old data
- **Forward**: Old schema can read new data
- **Full**: Both backward and forward compatible

---

## 5. CQRS Pattern Implementation

### What is CQRS?

**CQRS** = Command Query Responsibility Segregation

**Principle**: Separate read and write operations into different models.

### CQRS in This Project

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WRITE SIDE (Command)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Event Stream Service
    â†“ (write command: generate event)
Kafka (append-only log)
    â†“ (write command: index event)
Elasticsearch (write-optimized index)

Optimized for:
  - High throughput writes
  - Event sourcing
  - Append-only operations

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     READ SIDE (Query)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Dashboard UI / API Clients
    â†“ (read query: search events)
Elastic Query Service (REST API)
    â†“ (read query: full-text search)
Elasticsearch (read-optimized index)

Optimized for:
  - Fast queries
  - Full-text search
  - Pagination and filtering
  - Aggregations
```

### Benefits in This Project

| Benefit | How It's Achieved |
|---------|-------------------|
| **Independent Scaling** | Scale producers (write) and API (read) separately |
| **Optimized Data Models** | Avro for write, Elasticsearch for read |
| **Flexibility** | Add new read models without affecting writes |
| **Performance** | Write to Kafka (fast append), query Elasticsearch (optimized search) |

---

## 6. Project Structure

### Module Organization

```
spring-boot-microservices-with-kafka-demo/
â”œâ”€â”€ app-config-data/                    # Configuration data classes
â”‚   â””â”€â”€ src/main/java/.../config/
â”‚       â”œâ”€â”€ KafkaConfigData.java
â”‚       â”œâ”€â”€ KafkaProducerConfigData.java
â”‚       â”œâ”€â”€ KafkaConsumerConfigData.java
â”‚       â”œâ”€â”€ ElasticConfigData.java
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ common-config/                      # Shared configuration beans
â”‚   â””â”€â”€ src/main/java/.../config/
â”‚       â”œâ”€â”€ RetryConfig.java
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ common-security/                    # JWT, rate limiting, RBAC
â”‚   â””â”€â”€ src/main/java/.../security/
â”‚       â”œâ”€â”€ JwtTokenProvider.java
â”‚       â”œâ”€â”€ RateLimitingFilter.java
â”‚       â””â”€â”€ SecurityConfig.java
â”‚
â”œâ”€â”€ kafka/                              # Kafka-related modules
â”‚   â”œâ”€â”€ kafka-model/                    # Avro schema and generated classes
â”‚   â”‚   â””â”€â”€ src/main/resources/avro/
â”‚   â”‚       â””â”€â”€ social-event.avsc
â”‚   â”œâ”€â”€ kafka-admin/                    # Topic creation and management
â”‚   â”œâ”€â”€ kafka-producer/                 # Generic Avro producer
â”‚   â””â”€â”€ kafka-consumer/                 # Consumer interface
â”‚
â”œâ”€â”€ elastic/                            # Elasticsearch modules
â”‚   â”œâ”€â”€ elastic-model/                  # Document models
â”‚   â”œâ”€â”€ elastic-config/                 # Connection config
â”‚   â”œâ”€â”€ elastic-index-client/           # Indexing client
â”‚   â”œâ”€â”€ elastic-query-client/           # Query client
â”‚   â””â”€â”€ elastic-query-service/          # REST API service
â”‚
â”œâ”€â”€ event-stream-service/               # Producer microservice
â”‚   â””â”€â”€ src/main/java/.../
â”‚       â”œâ”€â”€ EventStreamServiceApplication.java
â”‚       â””â”€â”€ runner/
â”‚           â””â”€â”€ EnhancedMockStreamRunner.java
â”‚
â”œâ”€â”€ kafka-consumer-service/             # Consumer microservice
â”‚   â””â”€â”€ src/main/java/.../
â”‚       â”œâ”€â”€ KafkaConsumerServiceApplication.java
â”‚       â””â”€â”€ consumer/
â”‚           â””â”€â”€ SocialEventKafkaConsumer.java
â”‚
â”œâ”€â”€ kafka-streams-service/              # Streams microservice
â”‚   â””â”€â”€ src/main/java/.../
â”‚       â”œâ”€â”€ KafkaStreamsServiceApplication.java
â”‚       â””â”€â”€ topology/
â”‚           â””â”€â”€ SocialEventStreamsTopology.java
â”‚
â”œâ”€â”€ elasticsearch-service/              # Indexing microservice
â”‚   â””â”€â”€ src/main/java/.../
â”‚       â”œâ”€â”€ ElasticsearchIndexingServiceApplication.java
â”‚       â””â”€â”€ consumer/
â”‚           â””â”€â”€ SocialEventKafkaToElasticConsumer.java
â”‚
â”œâ”€â”€ dashboard-ui/                       # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ docker-compose/                     # Infrastructure
â”‚   â””â”€â”€ kafka_cluster.yml               # Kafka, Elasticsearch, Zookeeper
â”‚
â””â”€â”€ pom.xml                             # Parent Maven POM
```

### Shared Modules Pattern

**Benefits**:
- **Code Reuse**: Common configuration across services
- **Consistency**: Same Kafka/Elasticsearch config everywhere
- **Maintainability**: Change once, apply to all services

**Dependency Flow**:
```
event-stream-service
    â†“ depends on
kafka-producer
    â†“ depends on
kafka-model (Avro schemas)
    â†“ depends on
app-config-data
```

---

## 7. Environment Setup

### Prerequisites Checklist

âœ… **Java 21 (LTS)**
```bash
java -version
# Should output: openjdk version "21.0.x" or similar
```

âœ… **Maven 3.8+**
```bash
mvn -version
# Should output: Apache Maven 3.8.x or higher
```

âœ… **Docker & Docker Compose**
```bash
docker --version
docker-compose --version
# Ensure Docker Desktop is running
```

âœ… **Node.js 18+ & npm** (for Dashboard UI)
```bash
node --version  # v18.x or higher
npm --version   # 9.x or higher
```

âœ… **RAM**: Minimum 8GB, recommended 16GB
âœ… **Disk Space**: 20GB free

### Install Missing Dependencies

**Java 21** (if not installed):
```bash
# macOS (Homebrew)
brew install openjdk@21

# Ubuntu/Debian
sudo apt install openjdk-21-jdk

# Windows: Download from https://adoptium.net/
```

**Maven** (if not installed):
```bash
# macOS
brew install maven

# Ubuntu/Debian
sudo apt install maven

# Windows: Download from https://maven.apache.org/download.cgi
```

**Docker Desktop**:
- macOS/Windows: https://www.docker.com/products/docker-desktop
- Linux: https://docs.docker.com/engine/install/

---

## 8. Running the Project

### Step 1: Clone the Repository

```bash
git clone https://github.com/dsnanayakkara/spring-boot-microservices-with-kafka-demo.git
cd spring-boot-microservices-with-kafka-demo
```

### Step 2: Start Infrastructure

Start Kafka cluster, Elasticsearch, and supporting services:

```bash
cd docker-compose
docker-compose -f kafka_cluster.yml up -d
```

**Services Started**:
- Zookeeper (port 2181)
- Kafka Broker 1 (port 19092)
- Kafka Broker 2 (port 29092)
- Kafka Broker 3 (port 39092)
- Schema Registry (port 8081)
- Elasticsearch (port 9200)
- Kibana (port 5601)

**Wait for Services to Be Ready** (~60 seconds):
```bash
# Watch logs until you see "started" messages
docker-compose -f kafka_cluster.yml logs -f

# Or check individual service health
docker-compose -f kafka_cluster.yml ps
```

**Verify Kafka is Ready**:
```bash
# List topics (should show __consumer_offsets, _schemas, etc.)
docker exec -it kafka-broker-1 kafka-topics --bootstrap-server localhost:9092 --list
```

**Verify Elasticsearch is Ready**:
```bash
curl http://localhost:9200
# Should return JSON with cluster info
```

### Step 3: Build All Microservices

```bash
# Return to project root
cd ..

# Clean and build all modules (skip tests for faster build)
mvn clean install -DskipTests
```

**What This Does**:
- Compiles all Java code
- Generates Avro classes from schemas
- Packages each service as executable JAR
- Installs shared modules to local Maven repo

**Expected Output**:
```
[INFO] BUILD SUCCESS
[INFO] Total time: 2-3 minutes
```

### Step 4: Run Microservices

Open **5 separate terminal windows** (or tabs) and run each service:

**Terminal 1: Event Stream Service (Producer)**
```bash
cd event-stream-service
mvn spring-boot:run
```
Wait for: `Started EventStreamServiceApplication in X seconds`

**Terminal 2: Kafka Consumer Service**
```bash
cd kafka-consumer-service
mvn spring-boot:run
```
Wait for: `Started KafkaConsumerServiceApplication in X seconds`

**Terminal 3: Kafka Streams Service**
```bash
cd kafka-streams-service
mvn spring-boot:run
```
Wait for: `Started KafkaStreamsServiceApplication in X seconds`

**Terminal 4: Elasticsearch Service**
```bash
cd elasticsearch-service
mvn spring-boot:run
```
Wait for: `Started ElasticsearchIndexingServiceApplication in X seconds`

**Terminal 5: Elastic Query Service (REST API)**
```bash
cd elastic/elastic-query-service
mvn spring-boot:run
```
Wait for: `Started ElasticQueryServiceApplication in X seconds`

### Step 5: Start Dashboard UI

**Terminal 6: React Dashboard**
```bash
cd dashboard-ui
npm install           # First time only
npm run dev
```

**Access Dashboard**: http://localhost:3000

---

## 9. Verification and Testing

### Verify All Services Are Running

**Check Service Health Endpoints**:

```bash
# Event Stream Service
curl http://localhost:8080/actuator/health
# Expected: {"status":"UP"}

# Kafka Consumer Service
curl http://localhost:8081/actuator/health
# Expected: {"status":"UP"}

# Kafka Streams Service
curl http://localhost:8082/actuator/health
# Expected: {"status":"UP"}

# Elasticsearch Service
curl http://localhost:8083/actuator/health
# Expected: {"status":"UP"}

# Elastic Query Service (REST API)
curl http://localhost:8084/actuator/health
# Expected: {"status":"UP"}
```

### Verify Kafka Topics

```bash
docker exec -it kafka-broker-1 kafka-topics \
  --bootstrap-server localhost:9092 \
  --list
```

**Expected Topics**:
- `social-events`
- `social-events-filtered`
- `social-events-word-count`

### Verify Events Are Being Produced

```bash
# Consume from the beginning (will show all events)
docker exec -it kafka-broker-1 kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic social-events \
  --from-beginning \
  --max-messages 5
```

You should see Avro binary data (looks like gibberish), which is normal!

### Verify Elasticsearch Index

```bash
# Check if index exists
curl http://localhost:9200/_cat/indices?v

# Should show:
# health status index               docs.count
# green  open   social-events-index 120        ...

# Query some documents
curl http://localhost:9200/social-events-index/_search?size=3 | jq
```

### Test REST API

**Get All Events (Paginated)**:
```bash
curl http://localhost:8084/api/v1/events?page=0&size=5 | jq
```

**Search for Events**:
```bash
curl 'http://localhost:8084/api/v1/events/search?text=kafka' | jq
```

**Get Event by ID** (replace with actual ID from previous query):
```bash
curl http://localhost:8084/api/v1/events/1234567890 | jq
```

### View Dashboard

Open http://localhost:3000 in your browser.

**Expected UI**:
- Events list updating every 5 seconds
- Chart showing event timeline
- Statistics (total events, unique users)
- Service health indicators (all green)
- Search bar (try searching for "kafka")

### View API Documentation

Open http://localhost:8084/swagger-ui.html

**Try It Out**:
- Expand GET /api/v1/events
- Click "Try it out"
- Click "Execute"
- See response

---

## 10. Summary

### What You've Learned

âœ… The overall system architecture with 6 microservices
âœ… How each service fits into the data flow pipeline
âœ… CQRS pattern separating write and read paths
âœ… Infrastructure components (Kafka, Elasticsearch, Schema Registry)
âœ… How to set up and run the entire project locally
âœ… How to verify that all services are working correctly

### System Architecture Recap

```
Event Stream Service â†’ Kafka Cluster â†’ 3 Parallel Consumers:
                                        1. Consumer Service (logs metrics)
                                        2. Streams Service (analytics)
                                        3. Elasticsearch Service (indexes)
                                             â†“
                                        Elasticsearch Index
                                             â†“
                                        Elastic Query Service (REST API)
                                             â†“
                                        Dashboard UI
```

### Key Ports Reference

| Service | Port | URL |
|---------|------|-----|
| Event Stream Service | 8080 | http://localhost:8080/actuator/health |
| Kafka Consumer Service | 8081 | http://localhost:8081/actuator/health |
| Kafka Streams Service | 8082 | http://localhost:8082/actuator/health |
| Elasticsearch Service | 8083 | http://localhost:8083/actuator/health |
| Elastic Query Service | 8084 | http://localhost:8084/api/v1/events |
| Dashboard UI | 3000 | http://localhost:3000 |
| Kafka Broker 1 | 19092 | localhost:19092 |
| Schema Registry | 8081 | http://localhost:8081 |
| Elasticsearch | 9200 | http://localhost:9200 |
| Kibana | 5601 | http://localhost:5601 |

---

## Next Steps

Now that you understand the architecture and have the project running, you're ready to dive deep into event production!

ğŸ‘‰ **[Proceed to Module 3: Event Production & Avro Serialization](./03-event-production.md)**

---

## Troubleshooting

### Issue: Docker containers won't start

**Solution**:
```bash
# Check Docker is running
docker ps

# If not, start Docker Desktop

# Check available resources
docker system df

# Free up space if needed
docker system prune -a
```

### Issue: Port already in use

**Solution**:
```bash
# Find process using port 8080 (example)
lsof -i :8080

# Kill the process
kill -9 <PID>

# Or change port in application.yml:
server:
  port: 8090
```

### Issue: Kafka broker not reachable

**Solution**:
```bash
# Check broker logs
docker-compose -f kafka_cluster.yml logs kafka-broker-1

# Restart brokers
docker-compose -f kafka_cluster.yml restart

# If still failing, recreate
docker-compose -f kafka_cluster.yml down
docker-compose -f kafka_cluster.yml up -d
```

### Issue: Maven build fails

**Solution**:
```bash
# Clean Maven cache
rm -rf ~/.m2/repository

# Rebuild
mvn clean install -DskipTests -U
```

### Issue: Elasticsearch index not created

**Solution**:
```bash
# Check Elasticsearch service logs
cd elasticsearch-service
mvn spring-boot:run

# Look for errors related to index creation
# Manually create index:
curl -X PUT http://localhost:9200/social-events-index
```

---

## Exercises

### Exercise 1: Add a New Consumer

**Challenge**: Create a new consumer service that counts events per user and logs the top 10 users.

**Hints**:
- Create new Spring Boot project
- Add `@KafkaListener` with new group ID
- Use `ConcurrentHashMap<Long, AtomicLong>` to track counts
- Log top 10 every 30 seconds

### Exercise 2: Modify Event Schema

**Challenge**: Add a new field `sentiment` (POSITIVE/NEGATIVE/NEUTRAL) to the Avro schema.

**Steps**:
1. Update `social-event.avsc`
2. Regenerate classes: `mvn clean compile`
3. Update producer to set sentiment
4. Update consumers to read sentiment

**Question**: What happens to existing events without the field?

### Exercise 3: Dashboard Feature

**Challenge**: Add a pie chart showing event distribution by hour of day.

**Hints**:
- Extract hour from `createdAt` timestamp
- Use Recharts PieChart component
- Group events by hour
- Update chart on data refresh

---

**Module Progress**: 2 of 10 complete
